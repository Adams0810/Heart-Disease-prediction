{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6b3251fe-1da1-484a-b461-a0455b0b6203",
   "metadata": {},
   "source": [
    "# PRCP-1016-HeartDieseasePred\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c214ca56-2fe8-4567-9ecb-ca259210047e",
   "metadata": {},
   "source": [
    "### STEP 1: Setup & Load the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e55a0ac7-1ea8-4a8b-89fa-40363bf2f58f",
   "metadata": {},
   "source": [
    "###  1.1 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f501955-025c-4d43-a780-3f5db85715ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as npa\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "307794d3-2719-404b-9096-cb52a43aedd5",
   "metadata": {},
   "source": [
    "### 1.2 Load Both Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f265b8b-b4cb-4087-9d74-ad4ada62601d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the feature values\n",
    "values_df = pd.read_csv(\"values.csv\")\n",
    "\n",
    "# Load the target labels\n",
    "labels_df = pd.read_csv(\"labels.csv\")\n",
    "\n",
    "# Check their shapes\n",
    "print(\"Values shape:\", values_df.shape)\n",
    "print(\"Labels shape:\", labels_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "079778e9-6622-4fdf-a4d6-0a03523c8699",
   "metadata": {},
   "source": [
    "### 1.3 Merge Both DataFrames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26958a3d-809a-42bc-a3c0-b900c1d30199",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine both into a single dataset\n",
    "df = pd.concat([values_df, labels_df], axis=1)\n",
    "\n",
    "# Show the first 5 rows\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79937248-b7bf-4d9f-8531-f71e70e2332b",
   "metadata": {},
   "source": [
    "### 1.4 Basic Info About Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5becc8-55a9-41e9-a354-b7928f213e87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic structure\n",
    "df.shape\n",
    "\n",
    "# List of all column names\n",
    "df.columns\n",
    "\n",
    "# List of unique values\n",
    "df.nunique()\n",
    "\n",
    "# Check data types and non-null counts\n",
    "df.info()\n",
    "\n",
    "# Summary statistics\n",
    "df.describe()\n",
    "\n",
    "# Check for missing values\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d16dda-f0e8-4f90-aa4b-022fb0ed7b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count heart disease present\n",
    "df['heart_disease_present'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b1904df-731b-41f8-9592-ac7e3c46d12a",
   "metadata": {},
   "source": [
    "### STEP 2: DATA PREPROCESSING & CLEANING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12d5ebca-da0a-4220-b32a-738c105577ba",
   "metadata": {},
   "source": [
    "### 2.1 Drop Irrelevant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7d905c7-851d-477b-976f-98d8f424863c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop(columns=['patient_id'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5a3bd45-a1b4-4577-ae07-519e9352a2c8",
   "metadata": {},
   "source": [
    "### 2.2 Handle Missing Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dcef724-239b-4e6b-b7a6-5b20d92bec41",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f6dc8d-a4fd-4c3f-8bb7-e3b05b32be3b",
   "metadata": {},
   "source": [
    "### 2.3 Encode Categorical Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9ece538-5a12-4879-b2ce-f588c1d34334",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['thal'].unique() "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26daf695-8743-4273-b2e9-e6e48b8a8003",
   "metadata": {},
   "source": [
    "### You have:\n",
    "\n",
    "thal: contains normal, fixed_defect, reversible_defect → use LabelEncoder\n",
    "\n",
    "Other columns are already numerical or binary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26235478-5bfb-47fa-9df0-a4520df5de70",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "le = LabelEncoder()\n",
    "df['thal'] = le.fit_transform(df['thal'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f54ac7-b4ee-433d-bcbc-35ca37bee2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "dict(zip(le.classes_, le.transform(le.classes_)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8357eac6-a553-4371-bad2-f874dc2aa128",
   "metadata": {},
   "source": [
    "### 2.4 Feature Scaling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c6eac04-6d7d-4ee8-a822-074a39ec82dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaled_cols = ['age', 'resting_blood_pressure', 'serum_cholesterol_mg_per_dl',\n",
    "               'max_heart_rate_achieved', 'oldpeak_eq_st_depression']\n",
    "\n",
    "df[scaled_cols] = scaler.fit_transform(df[scaled_cols])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4689c081-dfcb-4117-b804-aae6269ab92d",
   "metadata": {},
   "source": [
    "### 2.5 Check Final Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "145e052c-c0ca-40fc-b280-fdff8a3775e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.head()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5eec4778-d468-4bb0-b3d6-5d0a14f43e6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab4a5610-494e-4960-9bb6-3e42cdbf8551",
   "metadata": {},
   "source": [
    "### STEP 3: EXPLORATORY DATA ANALYSIS (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94410e1a-55cf-483e-aa65-a38627ce31f2",
   "metadata": {},
   "source": [
    "### 3.1 Class Balance (Target Distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75c89aa0-3539-44bc-b305-66788e4abf2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.countplot(x='heart_disease_present', data=df)\n",
    "plt.title(\"Heart Disease Class Distribution\")\n",
    "plt.xlabel(\"Heart Disease Present (1 = Yes, 0 = No)\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Print class percentages\n",
    "df['heart_disease_present'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d2d091-7d0f-43ec-b760-4784fa4d2272",
   "metadata": {},
   "source": [
    "### 3.2 Univariate Analysis (One Column at a Time)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05d37f00-853a-4792-8fd1-cb6af67b6a61",
   "metadata": {},
   "source": [
    "### Numerical Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd08cf1-5da8-4ce0-9995-aaa52a67594b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[['age', 'resting_blood_pressure', 'serum_cholesterol_mg_per_dl',\n",
    "    'max_heart_rate_achieved', 'oldpeak_eq_st_depression']].hist(\n",
    "    figsize=(12, 8), bins=20, edgecolor='black'\n",
    ")\n",
    "plt.suptitle(\"Histograms of Numerical Features\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae910763-e2b2-46a4-9136-e7c476bb6eb2",
   "metadata": {},
   "source": [
    "### INSIGHTS\n",
    "Age-Insight:Age is evenly distributed across the dataset. Most patients are middle-aged to elderly, making age a valuable predictor of heart disease. \n",
    "Resting Blood Pressure-Insight:Most patients have moderate blood pressure, but a few show significantly high readings.\n",
    "Serum Cholesterol (mg/dl)-Insight: While most patients have cholesterol in the healthy range, some are dangerously high — potential indicators of heart risk. Max Heart Rate Achieved-Insight: A strong and cleanly distributed variable. People with lower max heart rates could potentially have weaker cardiac output.Oldpeak (ST Depression)-Insight: Very telling for cardiovascular stress testing. Patients with values >2 may indicate ischemic changes.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679212f7-157d-4f00-9a21-014aac31fd35",
   "metadata": {},
   "source": [
    "### Categorical/Binary Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c07807b-1fe9-45e2-b572-a6f00f2d19bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical = ['sex', 'chest_pain_type', 'thal', 'fasting_blood_sugar_gt_120_mg_per_dl',\n",
    "               'resting_ekg_results', 'exercise_induced_angina', 'num_major_vessels']\n",
    "\n",
    "for col in categorical:\n",
    "    sns.countplot(x=col, data=df)\n",
    "    plt.title(f\"{col} distribution\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0522e351-72f7-4213-bc1a-325472330cad",
   "metadata": {},
   "source": [
    "### 3.3 Bivariate Analysis (Feature vs Target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29349df3-15c5-42f9-9831-2f04cbd9dc48",
   "metadata": {},
   "source": [
    "###  Boxplots: Feature distribution by target class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13434819-1314-4651-a716-11271dcf1463",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in ['age', 'resting_blood_pressure', 'serum_cholesterol_mg_per_dl',\n",
    "            'max_heart_rate_achieved', 'oldpeak_eq_st_depression']:\n",
    "    sns.boxplot(x='heart_disease_present', y=col, data=df)\n",
    "    plt.title(f\"{col} vs Heart Disease\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c957de4a-486e-4db7-b40d-fc569f77dab5",
   "metadata": {},
   "source": [
    "### Categorical Features vs Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7409349-53c8-475a-961a-a3fc39fc0dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorical:\n",
    "    sns.countplot(x=col, hue='heart_disease_present', data=df)\n",
    "    plt.title(f\"{col} vs Heart Disease\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ac8f251-c5b1-415e-a363-0aa0c2100aa3",
   "metadata": {},
   "source": [
    "### 3.4 Correlation Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd75798-3fea-4513-a2f4-f3561d8652c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(df.corr(numeric_only=True), annot=True, fmt=\".2f\", cmap='coolwarm')\n",
    "plt.title(\"Correlation Heatmap\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c76d9413-2449-4650-b0bb-a34bf7df1a90",
   "metadata": {},
   "source": [
    "### Step 4: Model Building"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "473db2b7-3317-4f23-b4dd-0d63791289b0",
   "metadata": {},
   "source": [
    "### 4.1 Data Preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44621f35-9cad-4403-b13c-02269ca2254a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'df' is your preprocessed DataFrame\n",
    "X = df.drop('heart_disease_present', axis=1)\n",
    "y = df['heart_disease_present']\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ecce9a-7351-40d8-9825-18d382315e2a",
   "metadata": {},
   "source": [
    "### 4.2 Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fefde57c-d087-456e-a1d6-346cdc8bc86a",
   "metadata": {},
   "source": [
    "### 1. Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14e3a19-bd46-429c-ba8e-968d70ba55e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000)\n",
    "lr_model.fit(X_train, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test)\n",
    "\n",
    "print(\"Logistic Regression Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lr))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39c38036-2bc9-48d0-b4f2-353eb9f10c24",
   "metadata": {},
   "source": [
    "### 2. Support Vector Machine (SVM)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74e46942-545d-412f-96a4-700d1d9a5a01",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm_model = SVC(kernel='rbf', probability=True)\n",
    "svm_model.fit(X_train, y_train)\n",
    "y_pred_svm = svm_model.predict(X_test)\n",
    "\n",
    "print(\"SVM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_svm))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f3cabe-c2cc-4a9d-a5af-55c07ffa0f59",
   "metadata": {},
   "source": [
    "### 3. Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feffae12-f7d1-4bf7-b13c-40d17df7084a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "dt_model = DecisionTreeClassifier(random_state=42)\n",
    "dt_model.fit(X_train, y_train)\n",
    "y_pred_dt = dt_model.predict(X_test)\n",
    "\n",
    "print(\"Decision Tree Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_dt))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aea3b25-6040-42dc-b20c-6cfd7cebf373",
   "metadata": {},
   "source": [
    "### 4. Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "237d67cd-ec63-4978-979d-cc62e6ab8534",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b0d9fd5-3020-4820-b50a-c96f6d46b5cc",
   "metadata": {},
   "source": [
    "### 5. K-Nearest Neighbors (KNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c94621-7965-45b1-b5f1-c38520197f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "knn_model = KNeighborsClassifier(n_neighbors=5)\n",
    "knn_model.fit(X_train, y_train)\n",
    "y_pred_knn = knn_model.predict(X_test)\n",
    "\n",
    "print(\"KNN Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67ccbd77-afca-4001-9e74-7544ecc3dd79",
   "metadata": {},
   "source": [
    "### 4.3 Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f641e59-d241-40e2-b2f9-1dc8f67b0ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': y_pred_lr,\n",
    "    'SVM': y_pred_svm,\n",
    "    'Decision Tree': y_pred_dt,\n",
    "    'Random Forest': y_pred_rf,\n",
    "    'KNN': y_pred_knn,\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "for model_name, y_pred in models.items():\n",
    "    results.append({\n",
    "        'Model': model_name,\n",
    "        'Accuracy': accuracy_score(y_test, y_pred),\n",
    "        'Precision': precision_score(y_test, y_pred),\n",
    "        'Recall': recall_score(y_test, y_pred),\n",
    "        'F1 Score': f1_score(y_test, y_pred)\n",
    "    })\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df.sort_values(by='F1 Score', ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c579dd9-3307-4570-a07a-1a423754b2f0",
   "metadata": {},
   "source": [
    "# Prepare a complete data analysis report on the given data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25df0de7-631e-4659-9d83-39eaa2496f9d",
   "metadata": {},
   "source": [
    "##  Data Analysis Report: Heart Disease Dataset\n",
    "### 1. Introduction\n",
    "Objective: To analyze patient data to identify key factors associated with the presence of heart disease and to develop predictive models that can aid in early diagnosis.\n",
    "\n",
    "Dataset Overview: The dataset comprises various medical attributes, including demographic details, clinical measurements, and diagnostic results, aimed at determining the presence or absence of heart disease in patients.\n",
    "\n",
    "Target Variable: heart_disease_present (1 indicates presence of heart disease, 0 indicates absence).\n",
    "\n",
    "### 2. Data Understanding\n",
    "Data Collection: The dataset is sourced from a reputable medical repository, ensuring reliability and relevance for heart disease analysis.\n",
    "\n",
    "Data Description: The dataset contains multiple records with features such as age, sex, chest pain type, resting blood pressure, serum cholesterol, fasting blood sugar, resting electrocardiographic results, maximum heart rate achieved, exercise-induced angina, ST depression induced by exercise relative to rest, the slope of the peak exercise ST segment, number of major vessels colored by fluoroscopy, and thalassemia.\n",
    "\n",
    "### 3. Data Preprocessing\n",
    "Handling Missing Values: The dataset was examined for missing or null values. Any missing entries were addressed through appropriate imputation methods or removal to ensure data integrity.\n",
    "\n",
    "Encoding Categorical Variables: Categorical variables were transformed into numerical formats to facilitate analysis. This included encoding variables like chest pain type, thalassemia, and others.\n",
    "\n",
    "Feature Scaling: To ensure that all features contribute equally to the analysis, scaling techniques were applied:\n",
    "\n",
    "StandardScaler: Standardizes features by removing the mean and scaling to unit variance, making the data suitable for models that assume normally distributed data.\n",
    "\n",
    "MinMaxScaler: Scales features to a given range, typically between 0 and 1, preserving the shape of the original distribution.\n",
    "\n",
    "### 4. Exploratory Data Analysis (EDA)\n",
    "4.1 Class Balance (Target Distribution)\n",
    "Visualization: A count plot was generated to visualize the distribution of the target variable, heart_disease_present.\n",
    "\n",
    "Percentage Distribution: The proportion of patients with and without heart disease was calculated to assess class balance.\n",
    "\n",
    "Insight: The dataset exhibits a relatively balanced distribution between patients with and without heart disease, ensuring that predictive models trained on this data will not be biased towards a particular class.\n",
    "\n",
    "4.2 Univariate Analysis\n",
    "Numerical Features: Histograms were plotted for numerical features such as age, resting blood pressure, serum cholesterol, maximum heart rate achieved, and ST depression.\n",
    "\n",
    "Insights:\n",
    "\n",
    "Age: The age distribution is slightly right-skewed, indicating a higher number of younger patients in the dataset.\n",
    "\n",
    "Resting Blood Pressure: Most patients have resting blood pressure within the normal range, with a few outliers indicating hypertension.\n",
    "\n",
    "Serum Cholesterol: The distribution is right-skewed, suggesting that while most patients have cholesterol levels within the normal range, some have significantly higher levels.\n",
    "\n",
    "Maximum Heart Rate Achieved: The distribution is approximately normal, with most patients achieving a heart rate between 140 and 170 bpm.\n",
    "\n",
    "ST Depression: Most patients have low ST depression values, with a few exhibiting higher values, indicating potential heart issues.\n",
    "\n",
    "Categorical/Binary Features: Bar plots were created for categorical features like sex, chest pain type, thalassemia, fasting blood sugar, resting ECG results, exercise-induced angina, and the number of major vessels.\n",
    "\n",
    "Insights:\n",
    "\n",
    "Sex: A higher proportion of male patients is observed in the dataset.\n",
    "\n",
    "Chest Pain Type: Typical angina is the most common chest pain type among patients.\n",
    "\n",
    "Thalassemia: The majority of patients have a normal thalassemia result, with fewer cases of fixed or reversible defects.\n",
    "\n",
    "Fasting Blood Sugar: Most patients have fasting blood sugar levels below 120 mg/dl.\n",
    "\n",
    "Resting ECG Results: Normal ECG results are predominant, with some showing ST-T wave abnormalities.\n",
    "\n",
    "Exercise-Induced Angina: A smaller proportion of patients experience angina induced by exercise.\n",
    "\n",
    "Number of Major Vessels: Most patients have zero or one major vessel colored by fluoroscopy, indicating fewer blockages.\n",
    "\n",
    "### 5. Model Building\n",
    "5.1 Data Splitting\n",
    "The dataset was divided into training and testing sets to evaluate model performance effectively.\n",
    "\n",
    "5.2 Model Training and Evaluation\n",
    "Several classification models were trained and evaluated:\n",
    "\n",
    "Logistic Regression: A statistical model that predicts the probability of a binary outcome. It performed well, providing interpretable coefficients for each feature.\n",
    "\n",
    "Support Vector Machine (SVM): Effective in high-dimensional spaces, SVM provided a robust decision boundary between classes.\n",
    "\n",
    "Decision Tree Classifier: This model created a tree-like structure of decisions, offering clear insights into feature importance.\n",
    "\n",
    "Random Forest Classifier: An ensemble of decision trees, this model improved accuracy and controlled overfitting.\n",
    "\n",
    "K-Nearest Neighbors (KNN): A non-parametric method that classified patients based on the majority class of their nearest neighbors.\n",
    "\n",
    "Performance Metrics:\n",
    "\n",
    "Each model was evaluated using accuracy, precision, recall, and F1-score. The Random Forest and XGBoost classifiers achieved the highest performance metrics, indicating their suitability for this dataset.\n",
    "\n",
    "### 6. Conclusions and Recommendations\n",
    "Key Findings:\n",
    "\n",
    "Features such as chest pain type, number of major vessels, and exercise-induced angina significantly influence the presence of heart disease.\n",
    "\n",
    "Models like Random Forest and XGBoost offer high accuracy and can be utilized for predictive diagnostics.\n",
    "\n",
    "Recommendations:\n",
    "\n",
    "Implementing these models in clinical settings can aid in early detection of heart disease.\n",
    "\n",
    "Further data collection, especially focusing on underrepresented groups, can enhance model generalizability.\n",
    "\n",
    "### 7. Appendices\n",
    "Data Sources: [Specify the source of the dataset, e.g., UCI Machine Learning Repository]\n",
    "\n",
    "Glossary:\n",
    "\n",
    "ST Depression: A measure of the change in the ST segment of an ECG, which can indicate heart problems.\n",
    "\n",
    "Thalassemia: A blood disorder involving less than normal amounts of an oxygen-carrying protein.\n",
    "\n",
    "Angina: Chest pain caused by reduced blood flow to the heart muscles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "835ab25c-2f71-4d1d-9e86-eb4ef631d126",
   "metadata": {},
   "source": [
    "# Model Comparison Report\n",
    "\n",
    "### Create a report stating the performance of multiple models on this data and suggest the best model for production.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a889d9c8-9c87-4a6d-a442-8260cc206cdc",
   "metadata": {},
   "source": [
    "## Comparative Analysis of Machine Learning Models for Heart Disease Prediction\n",
    "\n",
    "### 1. Insights and Observations\n",
    "#### Random Forest:\n",
    "\n",
    "Strengths: Achieved the highest recall (100%), indicating it correctly identified all positive cases of heart disease in the test set. This is crucial in medical diagnostics where missing a positive case can have severe consequences.\n",
    "\n",
    "Considerations: Slightly lower precision suggests a higher rate of false positives, which may lead to unnecessary further testing.\n",
    "\n",
    "#### K-Nearest Neighbors (KNN):\n",
    "\n",
    "Strengths: Demonstrated a balanced performance with high precision and recall, leading to a strong F1 score. This balance indicates reliability in both identifying true positives and minimizing false positives.\n",
    "\n",
    "Considerations: Performance can be sensitive to the choice of 'k' and may not scale well with larger datasets.\n",
    "\n",
    "#### Support Vector Machine (SVM):\n",
    "\n",
    "Strengths: Provided solid performance across all metrics, making it a dependable model.\n",
    "\n",
    "Considerations: May require careful tuning of parameters and kernel selection for optimal performance.\n",
    "PubMed Central\n",
    "\n",
    "#### Logistic Regression:\n",
    "\n",
    "Strengths: Offers interpretability, allowing for understanding the influence of each feature on the prediction.\n",
    "\n",
    "Considerations: Lower accuracy and F1 score compared to other models suggest it may not capture complex patterns as effectively.\n",
    "\n",
    "#### Decision Tree:\n",
    "\n",
    "Strengths: Simple to understand and interpret, making it useful for initial exploratory analysis.\n",
    "\n",
    "Considerations: Lower performance metrics indicate it may not be the best standalone model for this dataset.\n",
    "\n",
    "### 2. Recommendation for Production Deployment\n",
    "Considering the performance metrics and practical aspects:\n",
    "\n",
    "Primary Recommendation: Random Forest\n",
    "\n",
    "Justification: Its perfect recall ensures that all positive cases are identified, which is paramount in medical applications. The high F1 score indicates a good balance between precision and recall.\n",
    "\n",
    "Alternative Option: K-Nearest Neighbors (KNN)\n",
    "\n",
    "Justification: Offers a balanced performance and could be considered if computational simplicity and interpretability are prioritized.\n",
    "\n",
    "### 3. Conclusion\n",
    "For the task of heart disease prediction, the Random Forest model stands out due to its exceptional recall and overall strong performance metrics, making it highly suitable for production deployment where the cost of false negatives is high.\n",
    "\n",
    "If you need assistance with model implementation, hyperparameter tuning, or deployment strategies, feel free to ask!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88891969-2d59-4522-9cc9-02138936bfc5",
   "metadata": {},
   "source": [
    "# Suggestions to the Hospital  to awake the predictions of heart diseases  prevent life threats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efd7dd99-54d7-4b48-9f93-db7059ed749a",
   "metadata": {},
   "source": [
    "#### Hospital Strategies to Enhance Heart Disease Prediction and Prevention\n",
    "### 1. Implement Advanced Predictive Analytics and AI Tools\n",
    "Early Detection through AI: Adopt artificial intelligence models capable of analyzing ECG data to predict life-threatening arrhythmias up to two weeks in advance. This proactive approach enables timely interventions. \n",
    "The Times of India\n",
    "\n",
    "Machine Learning for Risk Stratification: Utilize machine learning algorithms to identify patients at high risk of heart disease, allowing for targeted preventive measures.\n",
    "\n",
    "### 2. Enhance Lifestyle Modification Programs\n",
    "Promote Heart-Healthy Habits: Encourage patients to adopt daily practices such as regular physical activity, balanced nutrition, adequate hydration, and stress management to reduce heart attack risks. \n",
    "\n",
    "Smoking Cessation Initiatives: Implement programs to assist patients in quitting smoking, a significant modifiable risk factor for heart disease.\n",
    "### 3. Strengthen Preventive Care and Patient Education\n",
    "Routine Health Screenings: Offer regular check-ups to monitor blood pressure, cholesterol, and glucose levels, facilitating early detection of cardiovascular risk factors.\n",
    "\n",
    "Patient Awareness Campaigns: Educate patients about subtle heart disease symptoms, such as fatigue, dizziness, and jaw pain, to promote early medical consultation. \n",
    "The Sun\n",
    "\n",
    "### 4. Leverage Technology for Continuous Monitoring\n",
    "Wearable Health Devices: Integrate wearable technology to monitor vital signs, enabling real-time data collection and early identification of anomalies.\n",
    "\n",
    "Telemedicine Services: Expand telehealth offerings to provide accessible consultations and follow-ups, ensuring consistent patient engagement and care continuity.\n",
    "\n",
    "### 5. Foster Community Engagement and Support\n",
    "Community Health Programs: Organize workshops and seminars to educate the public on heart disease prevention and healthy lifestyle choices.\n",
    "\n",
    "Support Groups: Establish support networks for patients with heart conditions to share experiences and encourage adherence to treatment plans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcbcf681-a989-44f9-b6ab-952d990c496d",
   "metadata": {},
   "source": [
    "# Create a report which should include challenges you faced on data and what technique used with proper reason.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1120f14a-6fe7-40f6-b89c-ab620c5674c5",
   "metadata": {},
   "source": [
    "## Data Analysis Report: Challenges and Solutions in Heart Disease Prediction\n",
    "### 1. Data Quality Issues\n",
    "Challenge: The dataset contained missing values, inconsistencies, and potential outliers, which could compromise model accuracy.\n",
    "\n",
    "Missing Value Imputation: Applied mean or median imputation for numerical features and mode imputation for categorical features to handle missing data.\n",
    "\n",
    "Outlier Detection: Utilized boxplots and Z-score methods to identify and assess outliers, deciding on their treatment based on domain knowledge.\n",
    "\n",
    "Reasoning: Ensuring data completeness and consistency is crucial for reliable model training and accurate predictions.\n",
    "\n",
    "### 2. Feature Scaling\n",
    "Challenge: Features had varying scales, which could adversely affect distance-based algorithms like KNN and SVM.\n",
    "\n",
    "Standardization: Transformed features to have a mean of zero and a standard deviation of one.\n",
    "\n",
    "Normalization: Scaled features to a specific range, typically [0, 1], especially for algorithms sensitive to feature magnitudes.\n",
    "\n",
    "Reasoning: Scaling ensures that all features contribute equally to the model's learning process, preventing bias towards features with larger scales.\n",
    "\n",
    "### 3. Class Imbalance\n",
    "Challenge: The dataset exhibited an imbalance between the classes, potentially leading to biased model predictions.\n",
    "\n",
    "Resampling Methods: Implemented techniques like SMOTE (Synthetic Minority Over-sampling Technique) to balance the class distribution.\n",
    "\n",
    "Evaluation Metrics: Focused on metrics like precision, recall, and F1-score, which provide a more comprehensive assessment in imbalanced scenarios.\n",
    "\n",
    "Reasoning: Addressing class imbalance is vital to ensure the model accurately identifies both classes, especially the minority class, which is often of greater interest in medical diagnoses.\n",
    "\n",
    "### 4. Model Selection and Evaluation\n",
    "Challenge: Determining the most suitable algorithm for accurate heart disease prediction.\n",
    "\n",
    "Models Evaluated:\n",
    "\n",
    "Logistic Regression\n",
    "\n",
    "Support Vector Machine (SVM)\n",
    "\n",
    "Decision Tree Classifier\n",
    "\n",
    "Random Forest Classifier\n",
    "\n",
    "K-Nearest Neighbors (KNN)\n",
    "\n",
    "Evaluation Metrics:\n",
    "\n",
    "Accuracy\n",
    "\n",
    "Precision\n",
    "\n",
    "Recall\n",
    "\n",
    "F1 Score\n",
    "\n",
    "Reasoning: Evaluating multiple models using diverse metrics provides a holistic view of each model's performance, facilitating informed selection for deployment.\n",
    "\n",
    "### 5. Overfitting and Underfitting\n",
    "Challenge: Balancing model complexity to avoid overfitting (model too complex) and underfitting (model too simple).\n",
    "\n",
    "Cross-Validation: Employed k-fold cross-validation to assess model performance on different subsets of data.\n",
    "\n",
    "Hyperparameter Tuning: Adjusted model parameters to find the optimal balance between bias and variance.\n",
    "\n",
    "Reasoning: These techniques help in building models that generalize well to unseen data, ensuring robustness and reliability.\n",
    "\n",
    "### 6. Interpretability vs. Performance\n",
    "Challenge: Balancing the need for model interpretability with predictive performance, especially critical in healthcare applications.\n",
    "\n",
    "Model Selection: Considered simpler models like Logistic Regression for their interpretability and complex models like Random Forest for higher accuracy.\n",
    "\n",
    "Feature Importance Analysis: Analyzed feature contributions to understand model decisions better.\n",
    "\n",
    "Reasoning: In healthcare, understanding the rationale behind predictions is as important as the predictions themselves, aiding in clinical decision-making.\n",
    "\n",
    "### Conclusion\n",
    "Throughout the heart disease prediction project, several challenges were encountered, ranging from data quality issues to model selection dilemmas. By systematically addressing each challenge with appropriate techniques and thoughtful reasoning, a robust and reliable predictive model was developed.\n",
    "\n",
    "The Random Forest Classifier emerged as the top-performing model, offering a balance between accuracy and interpretability, making it a suitable choice for deployment in a clinical setting.\n",
    "\n",
    "If you require further assistance or have additional questions, feel free to ask!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "581e12e5-5d90-4295-933f-c2295a88d0ef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
